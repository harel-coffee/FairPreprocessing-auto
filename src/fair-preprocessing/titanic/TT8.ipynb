{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils.packages import *\n",
    "from utils.ml_fairness import *\n",
    "from utils.standard_data import *\n",
    "dir = 'res/titanic/'\n",
    "Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "d_fields = ['Name', 'Stage', 'CVR', 'CVD', 'V_SPD', 'V_EOD', 'V_AOD', 'V_ERD', 'Acc', 'F1','SPD', 'EOD', 'AOD', 'ERD']\n",
    "diff_file = dir + 'diff' + '.csv'\n",
    "if(not os.path.isfile(diff_file)):\n",
    "    with open(diff_file, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(d_fields)\n",
    "    \n",
    "f_count = len([name for name in os.listdir(dir) if os.path.isfile(os.path.join(dir, name)) and not name.startswith('.')])\n",
    "fields = ['Acc', 'F1', 'DI','SPD', 'EOD', 'AOD', 'ERD', 'CNT', 'TI']\n",
    "filename = dir + str(f_count) + '.csv'\n",
    "with open(filename, 'a') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    #If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def fill_missing_age(df):\n",
    "    \n",
    "    #Feature set\n",
    "    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp',\n",
    "                 'TicketNumber', 'Title','Pclass','FamilySize',\n",
    "                 'FsizeD','NameLength',\"NlengthD\",'Deck']]\n",
    "    # Split sets into train and test\n",
    "    train  = age_df.loc[ (df.Age.notnull()) ]# known Age values\n",
    "    test = age_df.loc[ (df.Age.isnull()) ]# null Ages\n",
    "    \n",
    "    # All age values are stored in a target array\n",
    "    y = train.values[:, 0]\n",
    "    \n",
    "    # All the other values are stored in the feature array\n",
    "    X = train.values[:, 1::]\n",
    "    \n",
    "    # Create and fit a model\n",
    "    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n",
    "    rtr.fit(X, y)\n",
    "    \n",
    "    # Use the fitted model to predict the missing values\n",
    "    predictedAges = rtr.predict(test.values[:, 1::])\n",
    "    \n",
    "    # Assign those predictions to the full data set\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../../../data/titanic/train.csv')\n",
    "test = pd.read_csv('../../../data/titanic/test.csv')\n",
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## BASIC PREP\n",
    "df['Sex'] = df['Sex'].replace({'female': 0.0, 'male': 1.0})\n",
    "\n",
    "y1_df = df.copy()\n",
    "## Custom(feature)\n",
    "df[\"Embarked\"] = df[\"Embarked\"].fillna('C')\n",
    "def fill_missing_fare(df):\n",
    "    median_fare=df[(df['Pclass'] == 3) & (df['Embarked'] == 'S')]['Fare'].median()\n",
    "    df[\"Fare\"] = df[\"Fare\"].fillna(median_fare)\n",
    "    return df\n",
    "df=fill_missing_fare(df)\n",
    "\n",
    "df[\"Deck\"]=df.Cabin.str[0]\n",
    "df.Deck.fillna('Z', inplace=True)\n",
    "\n",
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]+1\n",
    "\n",
    "df.loc[df[\"FamilySize\"] == 1, \"FsizeD\"] = 'singleton'\n",
    "df.loc[(df[\"FamilySize\"] > 1)  &  (df[\"FamilySize\"] < 5) , \"FsizeD\"] = 'small'\n",
    "df.loc[df[\"FamilySize\"] >4, \"FsizeD\"] = 'large'\n",
    "\n",
    "df[\"NameLength\"] = df[\"Name\"].apply(lambda x: len(x))\n",
    "bins = [0, 20, 40, 57, 85]\n",
    "group_names = ['short', 'okay', 'good', 'long']\n",
    "df['NlengthD'] = pd.cut(df['NameLength'], bins, labels=group_names)\n",
    "\n",
    "df[\"TicketNumber\"] = df[\"Ticket\"].str.extract('(\\d{2,})', expand=True)\n",
    "df[\"TicketNumber\"] = df[\"TicketNumber\"].apply(pd.to_numeric)\n",
    "df.TicketNumber.fillna(df[\"TicketNumber\"].median(), inplace=True)\n",
    "\n",
    "titles = df[\"Name\"].apply(get_title)\n",
    "df[\"Title\"] = titles\n",
    "# Titles with very low cell counts to be combined to \"rare\" level\n",
    "rare_title = ['Dona', 'Lady', 'Countess','Capt', 'Col', 'Don', \n",
    "                'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer']\n",
    "df.loc[df[\"Title\"] == \"Mlle\", \"Title\"] = 'Miss'\n",
    "df.loc[df[\"Title\"] == \"Ms\", \"Title\"] = 'Miss'\n",
    "df.loc[df[\"Title\"] == \"Mme\", \"Title\"] = 'Mrs'\n",
    "df.loc[df[\"Title\"] == \"Dona\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Lady\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Countess\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Capt\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Col\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Don\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Major\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Rev\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Sir\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Jonkheer\", \"Title\"] = 'Rare Title'\n",
    "df.loc[df[\"Title\"] == \"Dr\", \"Title\"] = 'Rare Title'\n",
    "\n",
    "labelEnc=LabelEncoder()\n",
    "cat_vars=['Embarked','Sex',\"Title\",\"FsizeD\",\"NlengthD\",'Deck']\n",
    "for col in cat_vars:\n",
    "    df[col]=labelEnc.fit_transform(df[col])\n",
    "\n",
    "df=fill_missing_age(df)\n",
    "\n",
    "drop_column = ['PassengerId', 'Cabin', 'Ticket', 'Name', 'Parch']\n",
    "df.drop(drop_column, axis=1, inplace = True)\n",
    "    \n",
    "\n",
    "std_scale = StandardScaler().fit(df[['Age', 'Fare']])\n",
    "df[['Age', 'Fare']] = std_scale.transform(df[['Age', 'Fare']])\n",
    "\n",
    "\n",
    "y1_df['Age'].fillna(y1_df['Age'].median(), inplace = True)\n",
    "y1_df = y1_df.fillna({\"Embarked\": \"S\"})\n",
    "y1_df['Cabin'].fillna(y1_df['Cabin'].mode(), inplace = True)\n",
    "\n",
    "# One-hot encoder\n",
    "cat_feat = ['Cabin', 'Ticket', 'Embarked']\n",
    "y1_df = pd.get_dummies(y1_df, columns=cat_feat, prefix_sep='=')\n",
    "\n",
    "y1_df = y1_df.drop(['PassengerId'], axis = 1)\n",
    "y1_df = y1_df.drop(['Name'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprinv: Sex 0.0\n",
      "Unprinv: Sex 0.0\n",
      "Unprinv: Sex 0.0\n",
      "Unprinv: Sex 0.0\n",
      "Unprinv: Sex 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    seed = randrange(100)\n",
    "    y2_train, y2_test = train_test_split(df, test_size = 0.3, random_state = seed) # stratify=df['loan']\n",
    "    y1_train, y1_test = train_test_split(y1_df, test_size = 0.3, random_state = seed) # \n",
    "\n",
    "    pro_att_name = ['Sex']\n",
    "    priv_class = [1]\n",
    "    reamining_cat_feat = []\n",
    "\n",
    "    y2_data_orig_train, y2_X_train, y2_y_train = load_titanic_data(y2_train, pro_att_name, priv_class, reamining_cat_feat)\n",
    "    y2_data_orig_test, y2_X_test, y2_y_test = load_titanic_data(y2_test, pro_att_name, priv_class, reamining_cat_feat)\n",
    "\n",
    "    y1_data_orig_train, y1_X_train, y1_y_train = load_titanic_data(y1_train, pro_att_name, priv_class, reamining_cat_feat)\n",
    "    y1_data_orig_test, y1_X_test, y1_y_test = load_titanic_data(y1_test, pro_att_name, priv_class, reamining_cat_feat)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y2_model = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=9,min_samples_split=6, min_samples_leaf=4)\n",
    "    y2_mdl = y2_model.fit(y2_X_train, y2_y_train)\n",
    "    \n",
    "    y1_model = RandomForestClassifier(random_state=1, n_estimators=50, max_depth=9,min_samples_split=6, min_samples_leaf=4)\n",
    "    y1_mdl = y1_model.fit(y1_X_train, y1_y_train)\n",
    "\n",
    "\n",
    "    # plot_model_performance(y2_mdl, y2_X_test, y2_y_test)\n",
    "    y1_pred, y1_fair = get_fair_metrics_and_plot(filename, y1_data_orig_test, y1_mdl)\n",
    "    y2_pred, y2_fair = get_fair_metrics_and_plot(filename, y2_data_orig_test, y2_mdl)\n",
    "\n",
    "\n",
    "\n",
    "    y1_fair = y1_fair.drop(['DI', 'CNT', 'TI'], axis=1)\n",
    "    y2_fair = y2_fair.drop(['DI', 'CNT', 'TI'], axis=1)\n",
    "    CVR, CVD, AVR_EOD, AVD_EOD, AVR_SPD, AVD_SPD, AVD_AOD, AV_ERD = compute_new_metrics(y2_data_orig_test, y1_pred, y2_pred)\n",
    "    row_y1 = y1_fair.iloc[[0]].values[0].tolist()\n",
    "    row_y2 = y2_fair.iloc[[0]].values[0].tolist()\n",
    "    diff = []\n",
    "\n",
    "    diff.append(CVR)\n",
    "    diff.append(CVD)\n",
    "    diff.append(AVD_SPD)\n",
    "    diff.append(AVD_EOD)\n",
    "    diff.append(AVD_AOD)\n",
    "    diff.append(AV_ERD)\n",
    "\n",
    "    for i in range(len(row_y2)):\n",
    "        if(i < 2):\n",
    "            change = row_y2[i] - row_y1[i]\n",
    "        else:\n",
    "            sign = ''\n",
    "            if(row_y2[i] >= 0 and row_y1[i] >= 0):\n",
    "                sign = '(+)'\n",
    "                d = abs(row_y2[i]) - abs(row_y1[i])\n",
    "            if(row_y2[i] < 0 and row_y1[i] < 0):\n",
    "                sign = '(-)'\n",
    "                d = abs(row_y2[i]) - abs(row_y1[i])\n",
    "            if(row_y2[i] < 0 and row_y1[i] >= 0):\n",
    "                sign = '(+-)'\n",
    "                d = row_y2[i] - row_y1[i]\n",
    "            if(row_y2[i] >=0 and row_y1[i] < 0):\n",
    "                sign = '(-+)'\n",
    "                d = row_y2[i] - row_y1[i]\n",
    "            d = round(d, 3)\n",
    "            change = sign + ' ' + str(d)\n",
    "\n",
    "        diff.append(change)\n",
    "\n",
    "    cols = ['CVR', 'CVD ', 'AV_SPD', 'AV_EOD', 'AV_AOD', 'AV_ERD', 'Acc', 'F1','SPD', 'EOD', 'AOD', 'ERD']\n",
    "    # metrics = pd.DataFrame(data=obj_fairness, index=['y1'], columns=cols)\n",
    "    diff_df = pd.DataFrame(data=[diff], columns  = cols, index = ['Diff']).round(3)\n",
    "    stage = 'Custom(feature)'\n",
    "    model_name = 'titanic8'\n",
    "    diff = diff_df.iloc[0].values.tolist()\n",
    "    diff.insert(0, stage)\n",
    "    diff.insert(0, model_name)\n",
    "    with open(diff_file, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(diff)    \n",
    "        diff_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
