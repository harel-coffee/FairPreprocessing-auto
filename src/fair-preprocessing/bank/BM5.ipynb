{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from utils.packages import *\n",
    "from utils.ml_fairness import *\n",
    "from utils.standard_data import *\n",
    "dir = 'res/bank/'\n",
    "Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "d_fields = ['Name', 'Stage', 'CVR', 'CVD', 'V_SPD', 'V_EOD', 'V_AOD', 'V_ERD', 'Acc', 'F1','SPD', 'EOD', 'AOD', 'ERD']\n",
    "diff_file = dir + 'diff' + '.csv'\n",
    "if(not os.path.isfile(diff_file)):\n",
    "    with open(diff_file, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(d_fields)\n",
    "    \n",
    "f_count = len([name for name in os.listdir(dir) if os.path.isfile(os.path.join(dir, name)) and not name.startswith('.')])\n",
    "fields = ['Acc', 'F1', 'DI','SPD', 'EOD', 'AOD', 'ERD', 'CNT', 'TI']\n",
    "filename = dir + str(f_count) + '.csv'\n",
    "with open(filename, 'a') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data: 10700 rows removed.\n"
     ]
    }
   ],
   "source": [
    "file_path = '../../data/bank/bank-additional-full.csv'\n",
    "\n",
    "column_names = []\n",
    "na_values=['unknown']\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';', na_values=na_values)\n",
    "\n",
    "### Drop na values\n",
    "dropped = df.dropna()\n",
    "count = df.shape[0] - dropped.shape[0]\n",
    "print(\"Missing Data: {} rows removed.\".format(count))\n",
    "df = dropped\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: np.float(x >= 25))\n",
    "\n",
    "# y1_df = df.copy()\n",
    "\n",
    "# df['poutcome'] = df['poutcome'].map({'failure': -1,'nonexistent': 0,'success': 1})\n",
    "# df['default'] = df['default'].map({'yes': -1,'unknown': 0,'no': 1})\n",
    "# df['housing'] = df['housing'].map({'yes': -1,'unknown': 0,'no': 1})\n",
    "# df['loan'] = df['loan'].map({'yes': -1,'unknown': 0,'no': 1})\n",
    "\n",
    "# nominal = ['job','marital','education','contact','month','day_of_week']\n",
    "# df = pd.get_dummies(df, columns=nominal)\n",
    "\n",
    "y1_nominal = ['job','marital','education','contact','month','day_of_week', 'poutcome', 'default', 'housing', 'loan']\n",
    "df = pd.get_dummies(df, columns=y1_nominal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y2_train, y2_test = train_test_split(df, test_size = 0.3, random_state = 0) #, stratify=df['race']\n",
    "# y2_train, y2_test = train_test_split(df, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprinv: age 0.0\n",
      "Unprinv: age 0.0\n",
      "Unprinv: age 0.0\n",
      "Unprinv: age 0.0\n",
      "Unprinv: age 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    pro_att_name = ['age'] # ['race', 'sex']\n",
    "    priv_class = [1] # ['White', 'Male']\n",
    "    reamining_cat_feat = []\n",
    "    seed = randrange(100)\n",
    "\n",
    "    y2_data_orig, y2_X, y2_y = load_bank_data(df, pro_att_name, priv_class, reamining_cat_feat)\n",
    "    y2_data_orig_train, y2_data_orig_test = y2_data_orig.split([0.7], shuffle=True, seed=seed)\n",
    "\n",
    "    y2_X_train = y2_data_orig_train.features\n",
    "    y2_y_train = y2_data_orig_train.labels.ravel()\n",
    "    y2_X_test = y2_data_orig_test.features\n",
    "    y2_y_test = y2_data_orig_test.labels.ravel()\n",
    "\n",
    "    y1_data_orig, y1_X, y1_y = load_bank_data(df, pro_att_name, priv_class, reamining_cat_feat)\n",
    "    y1_data_orig_train, y1_data_orig_test = y1_data_orig.split([0.7], shuffle=True, seed=seed)\n",
    "\n",
    "    y1_X_train = y1_data_orig_train.features\n",
    "    y1_y_train = y1_data_orig_train.labels.ravel()\n",
    "    y1_X_test = y1_data_orig_test.features\n",
    "    y1_y_test = y1_data_orig_test.labels.ravel()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    y2_X_train = sc.fit_transform(y2_X_train)\n",
    "    y2_X_test = sc.fit_transform(y2_X_test)\n",
    "    y2_data_orig_train.features = y2_X_train\n",
    "    y2_data_orig_test.features = y2_X_test\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.1], 'C': [1], 'probability': [True]}]\n",
    "    # Best parameter: 'C': 1, 'gamma': 0.1, 'kernel': 'rbf'\n",
    "\n",
    "    #SVC = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='precision')\n",
    "    y2_svc = SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
    "        max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
    "        verbose=False)\n",
    "    y2_mdl = y2_svc.fit(y2_X_train, y2_y_train)\n",
    "\n",
    "    #SVC = GridSearchCV(SVC(), tuned_parameters, cv=5, scoring='precision')\n",
    "    y1_svc = SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
    "        decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
    "        max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
    "        verbose=False)\n",
    "    y1_mdl = y1_svc.fit(y1_X_train, y1_y_train)\n",
    "\n",
    "\n",
    "\n",
    "    # plot_model_performance(y2_mdl, y2_X_test, y2_y_test)\n",
    "    y1_pred, y1_fair = get_fair_metrics_and_plot(filename, y1_data_orig_test, y1_mdl)\n",
    "    y2_pred, y2_fair = get_fair_metrics_and_plot(filename, y2_data_orig_test, y2_mdl)\n",
    "\n",
    "\n",
    "\n",
    "    y1_fair = y1_fair.drop(['DI', 'CNT', 'TI'], axis=1)\n",
    "    y2_fair = y2_fair.drop(['DI', 'CNT', 'TI'], axis=1)\n",
    "    CVR, CVD, AVR_EOD, AVD_EOD, AVR_SPD, AVD_SPD, AVD_AOD, AV_ERD = compute_new_metrics(y2_data_orig_test, y1_pred, y2_pred)\n",
    "    row_y1 = y1_fair.iloc[[0]].values[0].tolist()\n",
    "    row_y2 = y2_fair.iloc[[0]].values[0].tolist()\n",
    "    diff = []\n",
    "\n",
    "    diff.append(CVR)\n",
    "    diff.append(CVD)\n",
    "    diff.append(AVD_SPD)\n",
    "    diff.append(AVD_EOD)\n",
    "    diff.append(AVD_AOD)\n",
    "    diff.append(AV_ERD)\n",
    "\n",
    "    for i in range(len(row_y2)):\n",
    "        if(i < 2):\n",
    "            change = row_y2[i] - row_y1[i]\n",
    "        else:\n",
    "            sign = ''\n",
    "            if(row_y2[i] >= 0 and row_y1[i] >= 0):\n",
    "                sign = '(+)'\n",
    "                d = abs(row_y2[i]) - abs(row_y1[i])\n",
    "            if(row_y2[i] < 0 and row_y1[i] < 0):\n",
    "                sign = '(-)'\n",
    "                d = abs(row_y2[i]) - abs(row_y1[i])\n",
    "            if(row_y2[i] < 0 and row_y1[i] >= 0):\n",
    "                sign = '(+-)'\n",
    "                d = row_y2[i] - row_y1[i]\n",
    "            if(row_y2[i] >=0 and row_y1[i] < 0):\n",
    "                sign = '(-+)'\n",
    "                d = row_y2[i] - row_y1[i]\n",
    "            d = round(d, 3)\n",
    "            change = sign + ' ' + str(d)\n",
    "\n",
    "        diff.append(change)\n",
    "\n",
    "    cols = ['CVR', 'CVD ', 'AV_SPD', 'AV_EOD', 'AV_AOD', 'AV_ERD', 'Acc', 'F1','SPD', 'EOD', 'AOD', 'ERD']\n",
    "    # metrics = pd.DataFrame(data=obj_fairness, index=['y1'], columns=cols)\n",
    "    diff_df = pd.DataFrame(data=[diff], columns  = cols, index = ['Diff']).round(3)\n",
    "    stage = 'StandardScaler'\n",
    "    model_name = 'bank5'\n",
    "    diff = diff_df.iloc[0].values.tolist()\n",
    "    diff.insert(0, stage)\n",
    "    diff.insert(0, model_name)\n",
    "    with open(diff_file, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(diff)    \n",
    "        diff_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
