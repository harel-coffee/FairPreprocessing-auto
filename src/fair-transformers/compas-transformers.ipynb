{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from utils.packages import *\n",
    "from utils.ml_fairness import *\n",
    "from utils.standard_data import *\n",
    "dir = 'res/compas/'\n",
    "Path(dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "d_fields = ['Stage', 'CVR', 'CVD', 'V_SPD', 'V_EOD', 'V_AOD', 'V_ERD', 'Acc', 'F1','SPD', 'EOD', 'AOD', 'ERD']\n",
    "diff_file = dir + 'diff' + '.csv'\n",
    "if(not os.path.isfile(diff_file)):\n",
    "    with open(diff_file, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(d_fields)\n",
    "    \n",
    "f_count = len([name for name in os.listdir(dir) if os.path.isfile(os.path.join(dir, name)) and not name.startswith('.')])\n",
    "# fields = ['Acc', 'F1', 'DI','SPD', 'EOD', 'AOD', 'ERD', 'CNT', 'TI']\n",
    "fields = ['Acc', 'F1', 'SPD', 'EOD', 'AOD', 'ERD']\n",
    "\n",
    "filename = dir + 'glob-' + str(f_count) + '.csv'\n",
    "with open(filename, 'a') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = \"../../data/compas/compas.csv\"\n",
    "df = pd.read_csv(f_path)\n",
    "\n",
    "# Create a one-hot encoding of the categorical variables.\n",
    "# df = pd.get_dummies(df, columns=categorical_features, prefix_sep='=')\n",
    "\n",
    "## Basic data cleaning\n",
    "df['length_of_stay'] = (pd.to_datetime(df['c_jail_out'])-\n",
    "                          pd.to_datetime(df['c_jail_in'])).apply(lambda x: x.days)\n",
    "df['length_of_stay'].fillna(df['length_of_stay'].mode()[0], inplace = True)\n",
    "\n",
    "\n",
    "df.drop('c_jail_in', axis=1, inplace=True)\n",
    "df.drop('c_jail_out', axis=1, inplace=True)\n",
    "# del data['c_jail_in']\n",
    "# del data['c_jail_out']\n",
    "# Recode sex and race\n",
    "def group_race(x):\n",
    "    if x == \"Caucasian\":\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "df['sex'] = df['sex'].replace({'Female': 1.0, 'Male': 0.0})\n",
    "df['c_charge_degree'] = df['c_charge_degree'].replace({'F': 1.0, 'M': 0.0})\n",
    "df['race'] = df['race'].apply(lambda x: group_race(x))\n",
    "\n",
    "############### Pipeline ###############\n",
    "df = df[['sex','age','c_charge_degree','race','score_text',\n",
    "             'priors_count','days_b_screening_arrest','decile_score',\n",
    "             'is_recid','two_year_recid','length_of_stay']]\n",
    "\n",
    "\n",
    "df = df.loc[(df['days_b_screening_arrest'] <= 30)]\n",
    "df = df.loc[(df['days_b_screening_arrest'] >= -30)]\n",
    "\n",
    "df = df.loc[(df['is_recid'] != -1)]\n",
    "df = df.loc[(df['c_charge_degree'] != \"O\")]\n",
    "df = df.loc[(df['score_text'] != 'N/A')]\n",
    "\n",
    "impute1_and_onehot = Pipeline([('imputer1', SimpleImputer(strategy='mean')),\n",
    "                               ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "featurizer1 = ColumnTransformer(transformers=[\n",
    "        ('impute1_and_onehot', impute1_and_onehot, ['is_recid'])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "trans1 = pd.DataFrame(featurizer1.fit_transform(df[['is_recid']]), index=df.index, columns=['is_recid_no', 'is_recid_yes'])\n",
    "df = pd.concat([df, trans1], axis=1)\n",
    "df.drop('is_recid', axis=1, inplace=True)\n",
    "\n",
    "impute2_and_bin = Pipeline([('imputer2', SimpleImputer(strategy='mean')), # median, most_frequent,constant\n",
    "                            ('discretizer', KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='uniform'))]) # n_bins has effect\n",
    "featurizer2 = ColumnTransformer(transformers=[\n",
    "        ('impute2_and_bin', impute2_and_bin, ['age'])\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "df[['age']] = featurizer2.fit_transform(df[['age']])\n",
    "\n",
    "\n",
    "df = df.replace('Medium', \"Low\")\n",
    "df['score_text'] = LabelEncoder().fit_transform(df['score_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = randrange(100)\n",
    "y2_train, y2_test = train_test_split(df, test_size = 0.3, random_state = seed) # stratify=df['race']\n",
    "y1_train, y1_test = train_test_split(df, test_size = 0.3, random_state = seed) # \n",
    "\n",
    "pro_att_name = ['race']\n",
    "priv_class = [1]\n",
    "reamining_cat_feat = []\n",
    "\n",
    "y2_data_orig_train, y2_X_train, y2_y_train = load_compas_data(y2_train, pro_att_name, priv_class, reamining_cat_feat)\n",
    "y2_data_orig_test, y2_X_test, y2_y_test = load_compas_data(y2_test, pro_att_name, priv_class, reamining_cat_feat)\n",
    "\n",
    "y1_data_orig_train, y1_X_train, y1_y_train = load_compas_data(y1_train, pro_att_name, priv_class, reamining_cat_feat)\n",
    "y1_data_orig_test, y1_X_test, y1_y_test = load_compas_data(y1_test, pro_att_name, priv_class, reamining_cat_feat)\n",
    "y1_test_df = y1_data_orig_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.pipeline import Pipeline as Pipe\n",
    "# from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler, NearMiss, AllKNN\n",
    "# from imblearn.combine import SMOTEENN\n",
    "\n",
    "# over = SVMSMOTE(sampling_strategy='auto')\n",
    "# under = AllKNN(sampling_strategy='auto')\n",
    "# combine = SMOTEENN(sampling_strategy='auto')\n",
    "# step_over = [('o', over)] # , ('u', under)\n",
    "# step_under = [('u', under)] # , ('u', under)\n",
    "# step_combined = [('c', combine)] # , ('u', under)\n",
    "# # p = Pipe(steps=under)\n",
    "# y2_X_train, y2_y_train = combine.fit_resample(y2_X_train, y2_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sc = StandardScaler()\n",
    "# # sc = MinMaxScaler()\n",
    "# # sc = MaxAbsScaler()\n",
    "# # sc = RobustScaler()\n",
    "# # sc = Normalizer(norm='l1')\n",
    "\n",
    "# from sklearn.preprocessing import QuantileTransformer, PowerTransformer\n",
    "# # sc = QuantileTransformer()\n",
    "# # sc = PowerTransformer()\n",
    "# y2_X_train = sc.fit_transform(y2_X_train)\n",
    "# y2_X_test = sc.fit_transform(y2_X_test)\n",
    "# y2_data_orig_train.features = y2_X_train\n",
    "# y2_data_orig_test.features = y2_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFpr, SelectPercentile, VarianceThreshold\n",
    "# pca = PCA(n_components=5)\n",
    "# pca = SparsePCA(n_components=5)\n",
    "# pca = KernelPCA(n_components=5)\n",
    "\n",
    "# pca = SelectKBest(k=5)\n",
    "# pca = SelectFpr()\n",
    "pca = SelectPercentile()\n",
    "\n",
    "trained = pca.fit(y2_X_train, y2_y_train)\n",
    "y2_X_train = trained.transform(y2_X_train)\n",
    "y2_X_test = trained.transform(y2_X_test)\n",
    "y2_data_orig_test.features = y2_X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y2_dct = LogisticRegression()\n",
    "y1_dct = LogisticRegression()\n",
    "\n",
    "y2_rf = DecisionTreeClassifier()\n",
    "y1_rf = DecisionTreeClassifier()\n",
    "\n",
    "y2_xgb = XGBClassifier()\n",
    "y1_xgb = XGBClassifier()\n",
    "\n",
    "y2_svc = SVC()\n",
    "y1_svc = SVC()\n",
    "\n",
    "y2_gbc = KNeighborsClassifier(n_neighbors=10)\n",
    "y1_gbc = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "\n",
    "classifiers = [(y1_dct, y2_dct), (y1_rf, y2_rf), (y1_xgb, y2_xgb), (y1_svc, y2_svc), (y1_gbc, y2_gbc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprinv: race 0.0\n",
      "Unprinv: race 0.0\n",
      "Unprinv: race 0.0\n",
      "Unprinv: race 0.0\n",
      "Unprinv: race 0.0\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    y1_clf = clf[0]\n",
    "    y2_clf = clf[1]\n",
    "    \n",
    "    y2_mdl = y2_clf.fit(y2_X_train, y2_y_train)\n",
    "    y1_mdl = y1_clf.fit(y1_X_train, y1_y_train)\n",
    "\n",
    "    # plot_model_performance(y2_mdl, y2_X_test, y2_y_test)\n",
    "    y1_pred, y1_fair = get_fair_metrics_and_plot(filename, y1_data_orig_test, y1_mdl)\n",
    "    y2_pred, y2_fair = get_fair_metrics_and_plot(filename, y2_data_orig_test, y2_mdl)\n",
    "\n",
    "    y1_fair = y1_fair.drop(['DI', 'CNT', 'TI'], axis=1)\n",
    "    y2_fair = y2_fair.drop(['DI', 'CNT', 'TI'], axis=1)\n",
    "    \n",
    "    CVR, CVD, AVR_EOD, AVD_EOD, AVR_SPD, AVD_SPD, AVD_AOD, AV_ERD = compute_new_metrics(y1_data_orig_test, y1_pred, y2_pred)\n",
    "    row_y1 = y1_fair.iloc[[0]].values[0].tolist()\n",
    "    row_y2 = y2_fair.iloc[[0]].values[0].tolist()\n",
    "    diff = []\n",
    "    \n",
    "    with open(filename, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(row_y1)\n",
    "        csvwriter.writerow(row_y2) \n",
    "\n",
    "    diff.append(CVR)\n",
    "    diff.append(CVD)\n",
    "    diff.append(AVD_SPD)\n",
    "    diff.append(AVD_EOD)\n",
    "    diff.append(AVD_AOD)\n",
    "    diff.append(AV_ERD)\n",
    "\n",
    "    for i in range(len(row_y2)):\n",
    "        if(i < 2):\n",
    "            change = row_y2[i] - row_y1[i]\n",
    "        else:\n",
    "            sign = ''\n",
    "            if(row_y2[i] >= 0 and row_y1[i] >= 0):\n",
    "                sign = '(+)'\n",
    "                d = abs(row_y2[i]) - abs(row_y1[i])\n",
    "            if(row_y2[i] < 0 and row_y1[i] < 0):\n",
    "                sign = '(-)'\n",
    "                d = abs(row_y2[i]) - abs(row_y1[i])\n",
    "            if(row_y2[i] < 0 and row_y1[i] >= 0):\n",
    "                sign = '(+-)'\n",
    "                d = row_y2[i] - row_y1[i]\n",
    "            if(row_y2[i] >=0 and row_y1[i] < 0):\n",
    "                sign = '(-+)'\n",
    "                d = row_y2[i] - row_y1[i]\n",
    "            d = round(d, 3)\n",
    "            change = sign + ' ' + str(d)\n",
    "\n",
    "        diff.append(change)\n",
    " \n",
    "    cols = ['CVR', 'CVD', 'AV_SPD', 'AV_EOD', 'AV_AOD', 'AV_ERD', 'Acc', 'F1','SPD', 'EOD', 'AOD', 'ERD']\n",
    "    # metrics = pd.DataFrame(data=obj_fairness, index=['y1'], columns=cols)\n",
    "    diff_df = pd.DataFrame(data=[diff], columns  = cols, index = ['Diff']).round(3)\n",
    "    stage = 'Normalizer'\n",
    "    diff = diff_df.iloc[0].values.tolist()\n",
    "    diff.insert(0, stage)\n",
    "      \n",
    "    with open(diff_file, 'a') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(diff)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
